---
title: "Homework 1 - Group G"
author: "Matilde Castelli - Dogan Demirbilek - Eros Fabrici - Elena Peressi"
#output: html_notebook
output:
  html_document:
    toc: true
    toc_depth: 2
    theme: united
    highlight: tango
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# DAAG: **Data Analysis and Graphics Using R**

## Exercise 4.

For the data frame ais (DAAG package)
- Use the function `str()` to get information on each of the columns. Determine  whether any of the columns hold missing values.

```{r}
library(DAAG)
for (col in names(ais))
{
  str(ais[col])
}
#second method
str(ais)

#first option
#subset(ais,is.na(ais)) #select for columns

#second option
if(any(is.na(ais)))
{
  print("Some columns have Na Values")
}else
{ 
  print("No missing values")
}

```


- Make a table that shows the numbers of males and females for each different sport. In which sports is there a large imbalance (e.g., by a factor of more than 2:1) in the numbers of the two sexes?
  
```{r}
#?ais
# table of males anf females for each sport
t<-table(Sex=ais$sex, Sport=ais$sport)
t
#apply the function to all the columns of the table
title <- apply(t,2, max) > 2*apply(t,2, min)

#Sports with large imbalance
colnames(t)[title]

```

## Exercise 6.

Create a data frame called *Manitoba.lakes* that contains the lake’s elevation (in meters above sea level) and area (in square kilometers) as listed below. Assign the names of the lakes using the row.names() function.

```
				elevation 	area
Winnipeg 			217 	24387
Winnipegosis 		254 	5374
Manitoba 			248 	4624
SouthernIndian 		254 	2247
Cedar 				253 	1353
Island 				227 	1223
Gods 				178 	1151
Cross 				207 	755
Playgreen 			217 	657

```
```{r}
Manitoba.lakes <- data.frame(
    elevation = c(217, 254, 248, 254, 253, 227, 178, 207, 217),
    area = c(24387, 5374, 4624, 2247, 1353, 1223, 1151, 755, 657)
)
rows = c("Winnipeg", "Winnipegosis", "Manitoba", "SouthernIndian", "Cedar", "Island", "Gods", "Cross", "Playgreen")
row.names(Manitoba.lakes) <- rows
print(Manitoba.lakes)

```

(a) Use the following code to plot log2(area) versus elevation, adding labeling infor-
mation (there is an extreme value of area that makes a logarithmic scale pretty much
essential):

```
attach(Manitoba.lakes)
plot(log2(area)  ̃ elevation, pch=16, xlim=c(170,280))
# NB: Doubling the area increases log2(area) by 1.0
text(log2(area)  ̃ elevation,
labels=row.names(Manitoba.lakes), pos=4)
text(log2(area)  ̃ elevation, labels=area, pos=2)
title("Manitoba’s Largest Lakes")
detach(Manitoba.lakes)
```

Devise captions that explain the labeling on the points and on the y-axis. It will be necessary
to explain how distances on the scale relate to changes in area.

(b) Repeat the plot and associated labeling, now plotting area versus elevation, but
specifying log="y" in order to obtain a logarithmic y-scale. [Note: The log="y"
setting carries across to the subsequent text() commands. See Subsection 2.1.5 for an
example.]

```{r}
library(DAAG)
attach(Manitoba.lakes) 
plot(area ~ elevation, pch=16, xlim = c(170,260), log = "y")
text(area ~ elevation,
     labels=row.names(Manitoba.lakes), pos=4)
text(area ~ elevation, labels=area, pos=2)
title("Manitoba’s Largest Lakes")
detach(Manitoba.lakes)

```




## Exercise 11.

Run the following code:

```{r}
gender <- factor(c(rep("female", 91), rep("male", 92)))
table(gender)
gender <- factor(gender, levels=c("male", "female"))
table(gender)
gender <- factor(gender, levels=c("Male", "female")) 
# Note the mistake: "Male" should be "male"
table(gender)
table(gender, exclude=NULL)
rm(gender) # Remove gender
```

Explain the output from the successive uses of `table()`.
The first output shows a table with the counts of each factor level present in `gender`, which is a variable generated from the function `factor` which in turn encodes a vector as a factor. In our case, the vector is created with the merge of the vectors of characters `rep("female", 91)` and `rep("male", 92)` (`rep(a,b)` is a function that simply generates a vector by replicating `a`, `b` times) by using the function `c()` that takes an  aribitrary element of arguments and concatenates them into a single vector.

The second shows the same output, where `gender` is reassigned by using `factor` function, but in a different way. The variable `gender` itself is passed as an argument together with another vector, `c("male", "female")`, which indicates the levels of the new factor. In this case `factor` function will take the first argument, i.e. `gender`, and tranform each element in it that correspondes to one of the elements in the second argument, i.e. `"female"` and `"male"`, into a factor level with the same label (e.g. `"female"` is converted in factor level `female`), to `<NA>` (not available) otherwise.

In the third case, we are doing the same thing as steps as in the previous, but in the argument `levels` passed to `factors` there is a mistake: `c("Male", "female")` instead of `c("male", "female")`. Therefore, all the elements equal to `male` will be set as `<NA>` in the new factor. Consequently, `table(gender)` will count 0 for factor level `Male`.

Finally, `table(gender, exclude=NULL)` will show also the count of elements in `gender` that are marked as `<NA>`. The count was not shown in the third case due to the fact that `table`, by default, excludes all the elements that are `<NA>` or `<NaN>` (not a number). 

## Exercise 12.

Write a function that calculates the proportion of values in a vector x that exceed some value
cutoff.

1. Use the sequence of numbers 1, 2, . . . , 100 to check that this function gives the result that
   is expected.
2. Obtain the vector “ex01.36” from the Devore6 (or Devore7) package. These data give the times required for individuals to escape from an oil platform during a drill. Use dotplot() to show the distribution of times. Calculate the proportion of escape times that exceed 7 minutes.
```{r}

library(purrr) #lib for functional programming tools
library(Devore7)
#' Return the ration of elements in x that that exceed a cutoff value
#' @param x A vector/list of numeric values
#' @param cutoff A number 
#' @return Ratio of elements in x that exceed cutoff value
#' @examples
#' proportion_exceed(1:50, 25) -> 0.5
proportion_exceeding <- function(x, cutoff){
  if(!is.numeric(x) || !is.numeric(cutoff)){
    stop("Both arguments have to be numeric!")
  }
  
  n <- x %>% length
  n_exceeding <- x %>% keep(function(el) el > cutoff) %>% length
  return(n_exceeding/n)
}
proportion_exceeding(1:100, 99)


data(ex01.36)
dotplot(C1 ~ 1:length(C1), data = ex01.36, ylim=0:450,
        horizontal = FALSE, xlab="Individuals", ylab="Time (seconds)")

#proportion of the excape times that exceeds 7 minutes
proportion_exceeding(ex01.36$C1, 7*60) # ~3,85%



```

## Exercise 13.

The following plots four different transformations of the Animals data from the MASS package.
What different aspects of the data do these different graphs emphasize? Consider the effect on low values of the variables, as contrasted with the effect on high values.

```{r}
par(mfrow=c(2,2)) # 2 by 2 layout on the page
library(MASS) # Animals is in the MASS package
#?Animals
#body weight in kg, brain weight in g.
plot(brain ~  body, data=Animals)
plot(sqrt(brain) ~  sqrt(body), data=Animals)
plot(I(brain^0.1) ~  I(body^0.1), data=Animals)
# I() forces its argument to be treated "as is", ^ is treated as an arithmetic operator
plot(log(brain) ~ log(body), data=Animals)
par(mfrow=c(1,1)) # Restore to 1 figure per page
```


## Exercise 15.

The data frame `socsupport` (DAAG) has data from a survey on social and other kinds of support, for a group of university students. It includes `Beck Depression Inventory` (BDI) scores.

The following are two alternative plots of BDI against age:

```R
plot(BDI ˜ age, data=socsupport)
plot(BDI ˜ unclass(age), data=socsupport)
```

- For examination of cases where the score seems very high, which plot is more useful? Explain.

Individual value plot is more useful to examination of cases. Both plots are useful to assess central tendency, variability and identify outliers. However box-plots present ranges of values based on quartiles and when sample size is too small, the quartile estimates might not be meaningful. Therefore it is more logical to use individual value plot to examine cases.

- Why is it necessary to be cautious in making anything of the plots for students in the three oldest age categories (25-30, 31-40, 40+)?

Three oldest age categories (25-30, 31-40, 40+) are also has the least number of observations and plots such as boxplots may estimate the properties of those age categories while plottoing them. Those estimations will not be meaningfull when sample size is too small. Therefore it is necessary to be cautious about those age categories.



## Exercise 17.

Given a vector x, the following demonstrates alternative ways to create a vector of numbers from 1 through n, where n is the length of the vector:

```
x <- c(8, 54, 534, 1630, 6611)
seq(1, length(x))
seq(along=x)
```


Now set `x <- NULL` and repeat each of the calculations `seq(1, length(x))` and `seq(along=x).` 

Which version of the calculation should be used in order to return a vector of length 0 in the event that the supplied argument is `NULL.`

The second, because `seq(1, length(x))` is interpreted as `seq(from = 1, to = 0)` therefore producing the vector `[1,0]`, while `seq(along=x)` should generate a sequence `1, 2, ..., lenght(x)` but as `length(x)` is equal to 0, it will return a vector of lenght 0.

```{r}
x <- NULL
seq(1, length(x))
seq(along=x)
```


#### Exercise 20

The help page for iris (type help(iris)) gives code that converts the data in
iris3 (datasets package) to case-by-variable format, with column names “Sepal.Length”,“Sepal.Width”, “Petal.Length”, “Petal.Width”, and “Species”. Look up the help pages for the functions that are used, and make sure that you understand them. Then add annotation to this code that explains each step in the computation.

-----

# CS: **Core Statistics**

## Exercise 1.1

Exponential random variable, X ≥ 0, has p.d.f. f(x) = λ exp(−λ^x).

1. Find the c.d.f. and the quantile function for X.

To find c.d.f of $f(x)$, we need to integrate it from $0$ to $x$.

$$
f(x) = \lambda e^{-\lambda x} \\
F(x) = P(X \leq x) \\
     = \int_{0}^{x} f(w) \; dw \\
     = \int_{0}^{x} \lambda e^{-\lambda w} \; dw \\
     = [-\lambda e^{-\lambda w}]_{0}^{x} \\
     = 1 - e^{-\lambda x} \\
$$

The quantile function (inverse c.d.f)

$$
     1 - e^{-\lambda Q} = p \\
     Q(p; \lambda) = \frac{\ln(1-p)}{\lambda}
$$

2. Find Pr(X < λ) and the median of X.

By using c.d.f function that we found before
$Pr(X < λ) = 1 - e^{-\lambda^2}$

Median is
$$
Q(p = \frac{2}{4}; \lambda)\\
=-\ln(1/2)\lambda
$$

3. Find the mean and variance of X.
Mean
$$
E[X] = \int_{0}^{+\infty} xf(x) \; dx \\
     = \int_{0}^{+\infty} x\lambda e^{-\lambda x} \; dx  \\
     = \left[-x e^{-\lambda x}\right]_{0}^{\infty} + \int_{0}^{\infty}e^{-\lambda x}dx   \\
     = (0-0) + \left[\frac{-1}{\lambda}-e^{-\lambda x} \right]_{0}^{\infty} \\
     = 0 + \left(0 + \frac{1}{\lambda}\right)
     = \frac{1}{\lambda}
$$
Variance
$$
E[X^2] = \int_{-\infty}^{+\infty} x^2f(x) \; dx \\
= \int_{0}^{+\infty} x^2\lambda e^{-\lambda x} \; dx \\
= \left[-x^2e^{-\lambda x}\right]_{0}^{\infty} + \int_{0}^{\infty}2xe^{-\lambda x}dx \\
= (0-0) + \left[\frac{-2}{\lambda}  x e^{-\lambda x}\right]_{0}^{\infty} + \frac{2}{\lambda} \int_{0}^{\infty}e^{-\lambda x}dx\\
= (0-0) +\frac{2}{\lambda} \left[\frac{-1}{\lambda}e^{-\lambda x}  \right]_{0}^{\infty}
= \frac{2}{\lambda^2}\\
Var[X] = E[X^2] - E[X]^2\\
We \space already \space know \space E[X] = \frac{1}{\lambda}\\
Var[X] = \frac{2}{\lambda^2} - \frac{1}{\lambda^2} = \frac{1}{\lambda^2}
$$



## Exercise 1.2

Evaluate Pr(X < 0.5, Y < 0.5) if X and Y have joint p.d.f. (1.2).

$$
Pr(X<0.5, Y<0.5) = F_{X,Y}(0.5, 0.5)\\
= \int_{-\infty}^{0.5}\int_{-\infty}^{0.5}f_{X,Y}(x,y)\;dydx
$$

## Exercise 1.6

Let X and Y be non-independent random variables, such that $var(X) = σ^2_x$, $var(Y ) = σ^2_y$ and $cov(X, Y ) = σ^2_{xy}$. Using the result from Section 1.6.2, find var(X + Y) and var(X − Y).

As $X$ $Y$ are dependent, we have that
$$
Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y)\\
= \sigma^2_x + \sigma^2_y + 2\sigma^2_{xy}\\

Var(X-Y) = Var(X) + Var(Y) - 2Cov(X,Y)\\
= \sigma^2_x + \sigma^2_y - 2\sigma^2_{xy}
$$

## Exercise 1.8

If $log(X) ∼ N(μ, σ^2)$, find the p.d.f. of X.

## Exercise 1.9

Discrete random variable Y has a Poisson distribution with parameter λ if its p.d.f. is $f(y) = λ^ye^{−\lambda}/y!$, for $y = 0, 1,$ . . .

1. Find the moment generating function for Y (hint: the power series representation of the exponential function is useful).
2. If Y1 ∼ Poi(λ1) and independently Y2 ∼ Poi(λ2), deduce the distribution of Y1 + Y2, by employing a general property of m.g.f.s.
3. Making use of the previous result and the central limit theorem, deduce the normal approximation to the Poisson distribution.
4. Confirm the previous result graphically, using R functions dpois, dnorm, plot or barplot and lines. Confirm that the approximation improves with increasing λ

# LAB: **Laboratory**

## Exercise 1
Write a function binomial(x,n,p) for the binomial distribution above, depending on parameters x,n,p, and test it with some prespecified values. Use the function choose() for the binomial coefficient.
Plot two binomials with n=20, and p=0.3,0.6 respectively.


The r.v. $X$ that counts the number of successes has **binomial distribution** with probability
function
$$
{\rm Pr}(X = x) = \binom{n}{x} p^x \, (1-p)^{n-x} \, , \hspace{1cm} x = 0,\ldots,n\, .
$$

```{r}
mybinom <- function(x,n,p){
  return( choose( n,x )*( p^{x} )*( (1-p)^{n-x} ) )
}
#test
print("n = 20, p=0.3")
mybinom(0:20,20,0.2)
print("p=0.3")
mybinom(0:20,20,0.3)
print("p=0.6")
mybinom(0:20,20,0.6)

```

```{r}
# plot
par(mfrow=c(1,2),mar=c(4,4,2,1),oma=c(0,0.2,0.2,0), pty="s", pch = 16)
plot(0:20, mybinom(0:20, 20, 0.3), 
     xlab = "x", ylab = "f(x)", cex.lab=1.5, main="n=20, p = 0.3", cex.main=1.5, col = 'blue')
plot(0:20, mybinom(0:20, 20, 0.6), 
     xlab = "x", ylab = "f(x)", cex.lab=1.5, main="n=20, p = 0.6", cex.main=1.5, col = 'blue')
```

 
## Exercise 2
- Generate in $\mathsf{R}$ the same output, but using $\mathsf{rgeom()}$ for generating the random variables. *Hint*: generate $n$ times three geometric distribution $X_1,\ldots, X_3$ with $p=0.08$, store them in a matrix and compute then the sum $Y$. 

```{r}
matrix_mini <-  matrix(data = NA, nrow = 1000, ncol = 4)

for (j in 1:3) {
  for (k in 1:1000) {
      matrix_mini[k, j] = rgeom(1,0.08)
  };
};


matrix_mini[,4] <- rowSums(matrix_mini[,1:3])

hist(matrix_mini[,4])

```




## Exercise 3
- Show in $\mathsf{R}$, also graphically, that $\mbox{Gamma}(n/2, 1/2)$ coincides with a $\chi^{2}_{n}$.

$$
Gamma(x;\frac{n}{2}, \frac{1}{2}) = \frac{\bigg( \frac{1}{2} \bigg)^{\frac{1}{2}}}{\Gamma(\frac{n}{2})}x^{\frac{n}{2}-1}e^{-\frac{x}{2}}\\
= \frac{1}{2^{\frac{n}{2}}\Gamma(\frac{n}{2})} x^{\frac{n}{2}-1}e^{-\frac{n}{2}} = \chi^2_n(x)
$$

```{r}
d_of_freedom <- 1000; alpha <- d_of_freedom/2; beta <- 1/2;
curve(dchisq(x, d_of_freedom), col="red", xlim=c(800, 1200), lwd = 3, ylab = "Density")
curve(dgamma(x, alpha, beta), col="blue", xlim=c(800, 1200), lwd = 1, add = TRUE)
```

- Find the 5\% and the 95\% quantiles of a $\mbox{Gamma}(3,3)$. 

```{r}
qgamma(0.05, 3, 3)
qgamma(0.95, 3, 3)
```


## Exercise 4

- Generate $n=1000$ values from a $\mbox{Beta}(5,2)$ and compute the sample mean and the sample variance.


## Exercise 5
- Analogously, show with a simple $\mathsf{R}$ function that a negative binomial distribution may be seen as a mixture between a Poisson and a Gamma. In symbols: $X|Y \sim \mathcal{P}(Y)$, $Y \sim \mbox{Gamma}(\alpha, \beta)$, then $X \sim \ldots$.

## Exercise 6

- Instead of using the built-in function $\mathsf{ecdf()}$, write your own $\mathsf{R}$ function for the empirical cumulative distribution function and reproduce the two plots above.

```{r}
my_ecdf <-  function(sample, x=NULL){
  
  sample <- sort(unique(sample))
  
  if(is.null(x)){
    ecdf_sample <- (1:length(sample)) / length(sample) 
    ecdf_sample
  }
  
  else {
    minors <- 0
    for(n in sample){
      if(n <= x ){
        minors = minors + 1
      }
    };
    minors/ length(sample)
  }
}


set.seed(2)
par(mfrow=c(1,2))
n<-50
y<-rbeta(n, 3,4)
edf_beta <- sort(y)
tt<-seq(from=0, to=1, by=0.01)
plot(edf_beta, my_ecdf(edf_beta), main="ECDF and CDF: n=50",pch = 19,xlab = "x",ylab = "Fn(x)")
abline(h = c(0,1), col = "gray70", lty = 2)
lines(tt, pbeta(tt,3,4), col=2, lty=2, lwd=2)

n2<-500
y2<-rbeta(n2, 3,4)
edf_beta <- sort(y2)
tt<-seq(from=0, to=1, by=0.01)
plot(edf_beta, my_ecdf(edf_beta), main="ECDF and CDF: n=500",pch = 19,xlab = "x",ylab = "Fn(x)")
abline(h = c(0,1), col = "gray70", lty = 2)
lines(tt, pbeta(tt,3,4), col=2, lty=2, lwd=2)

```

## Exercise 7

Compare in $\mathsf{R}$ the assumption of normality for these samples:

- $y_1, \ldots, y_{100} \sim t_{\nu},$ with $\nu=5,20, 100$. What does it happens when the number of degrees of freedom $\nu$ increases?

- $y_1, \ldots, y_{100} \sim \mbox{Cauchy}(0,1)$. Do you note something weird for the extremes quantiles? 


## Exercise 8

- Write a general $\mathsf{R}$ function for checking the validity of the central limit theorem. *Hint* The function will consist of two parameters: clt_function <- function($\mathsf{n}$, $\mathsf{distr}$), where the first one is the sampe size and the second one is the kind of distribution from which you generate. Use plots for visualizing the results.
